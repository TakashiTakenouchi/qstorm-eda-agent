#!/usr/bin/env python3
"""
Store Data Histogram Distribution Analyzer Agent
=================================================

æµæ¯”å¯¿åº—ãƒ»æ¨ªæµœå…ƒç”ºåº—ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ä½œæˆã—ã€
ç¢ºç‡åˆ†å¸ƒï¼ˆæ­£è¦åˆ†å¸ƒ/ãƒã‚¢ã‚½ãƒ³åˆ†å¸ƒ/è² ã®äºŒé …åˆ†å¸ƒï¼‰ã‚’åˆ¤å®šã—ã¦
è‡ªç„¶è¨€èªã§è§£èª¬ã™ã‚‹AI Agentã€‚

ä½¿ç”¨æ–¹æ³•:
    # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰
    uv run python store_histogram_agent.py

    # å˜ä¸€ã‚«ãƒ©ãƒ åˆ†æ
    uv run python store_histogram_agent.py --column Total_Sales

    # å…¨ã‚«ãƒ©ãƒ åˆ†æ
    uv run python store_histogram_agent.py --all

    # ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«
    uv run python store_histogram_agent.py --file path/to/data.xlsx
"""

import asyncio
import json
import os
import sys
from pathlib import Path
from typing import Any

import matplotlib
matplotlib.use('Agg')  # Non-interactive backend
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from scipy import stats

from claude_agent_sdk import (
    ClaudeAgentOptions,
    ClaudeSDKClient,
    ResultMessage,
    AssistantMessage,
    TextBlock,
    ToolUseBlock,
    create_sdk_mcp_server,
    tool,
)


# =============================================================================
# å®šæ•°å®šç¾©
# =============================================================================

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
DEFAULT_DATA_PATH = r"C:\Users\ç«¹ä¹‹å†…éš†\Documents\MBS_Lessons\MBS2025\Data Set\Ensuring consistency between tabular data and time series forecast data\fixed_extended_store_data_2024-FIX_kaizen_monthlyvol6_new.xlsx"

# åˆ†æå¯¾è±¡ã‚«ãƒ©ãƒ 
TARGET_COLUMNS = [
    "shop",
    "shop_code",
    "Total_Sales",
    "gross_profit",
    "discount",
    "purchasing",
    "rent",
    "personnel_expenses",
    "depreciation",
    "sales_promotion",
    "head_office_expenses",
    "operating_cost",
    "Operating_profit",
    "Mens_JACKETS&OUTER2",
    "Mens_KNIT",
    "Mens_PANTS",
    "WOMEN'S_JACKETS2",
    "WOMEN'S_TOPS",
    "WOMEN'S_ONEPIECE",
    "WOMEN'S_bottoms",
    "WOMEN'S_SCARF & STOLES",
    "Inventory",
    "Months_of_inventory",
    "BEP",
    "Average_Temperature",
    "Number_of_guests",
    "Price_per_customer",
]

# ã‚«ãƒ©ãƒ åã®æ—¥æœ¬èªå®šç¾©
COLUMN_DEFINITIONS = {
    "shop": "åº—èˆ—åç§°",
    "shop_code": "åº—èˆ—ã‚³ãƒ¼ãƒ‰",
    "Total_Sales": "å£²ä¸Šé«˜",
    "gross_profit": "ç²—åˆ©",
    "discount": "å€¤å¼•ã",
    "purchasing": "ä»•å…¥",
    "rent": "å®¶è³ƒ",
    "personnel_expenses": "äººä»¶è²»",
    "depreciation": "æ¸›ä¾¡å„Ÿå´è²»ç”¨",
    "sales_promotion": "è²©å£²ä¿ƒé€²è²»",
    "head_office_expenses": "æœ¬ç¤¾è²»ç”¨",
    "operating_cost": "æ¥­å‹™è²»ç”¨",
    "Operating_profit": "å–¶æ¥­åˆ©ç›Š",
    "Mens_JACKETS&OUTER2": "ç”·æ€§ç”¨JACKETS&OUTERå£²ä¸Šé«˜",
    "Mens_KNIT": "ç”·æ€§ç”¨KNITå£²ä¸Šé«˜",
    "Mens_PANTS": "ç”·æ€§ç”¨PANTSå£²ä¸Šé«˜",
    "WOMEN'S_JACKETS2": "å¥³æ€§ç”¨JACKETSå£²ä¸Šé«˜",
    "WOMEN'S_TOPS": "å¥³æ€§ç”¨TOPSå£²ä¸Šé«˜",
    "WOMEN'S_ONEPIECE": "å¥³æ€§ç”¨ONEPIECEå£²ä¸Šé«˜",
    "WOMEN'S_bottoms": "å¥³æ€§ç”¨bottomså£²ä¸Šé«˜",
    "WOMEN'S_SCARF & STOLES": "å¥³æ€§ç”¨SCARF&STOLESå£²ä¸Šé«˜",
    "Inventory": "åœ¨åº«é‡‘é¡",
    "Months_of_inventory": "åœ¨åº«æœˆæ•°",
    "BEP": "æç›Šåˆ†å²ç‚¹",
    "Average_Temperature": "å¹³å‡æ°—æ¸©",
    "Number_of_guests": "å®¢æ•°",
    "Price_per_customer": "å®¢å˜ä¾¡",
}


# =============================================================================
# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
# =============================================================================

SYSTEM_PROMPT = """
ã‚ãªãŸã¯å°å£²åº—èˆ—ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆè§£æå°‚é–€å®¶ã§ã™ã€‚

## å½¹å‰²
æµæ¯”å¯¿åº—ãƒ»æ¨ªæµœå…ƒç”ºåº—ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€å„é …ç›®ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‹ã‚‰
æœ€é©ãªç¢ºç‡åˆ†å¸ƒã‚’ç‰¹å®šã—ã€ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’å«ã‚ã¦æ—¥æœ¬èªã§è§£èª¬ã—ã¾ã™ã€‚

## ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
- å¯¾è±¡åº—èˆ—: æµæ¯”å¯¿åº—ã€æ¨ªæµœå…ƒç”ºåº—
- ãƒ‡ãƒ¼ã‚¿ç¨®é¡: æœˆæ¬¡ã®å£²ä¸Šãƒ»æç›Šãƒ‡ãƒ¼ã‚¿
- åˆ†æé …ç›®: å£²ä¸Šé«˜ã€ç²—åˆ©ã€å„ã‚«ãƒ†ã‚´ãƒªå£²ä¸Šã€åœ¨åº«ã€å®¢æ•°ãªã©

## åˆ†ææ‰‹é †
1. load_store_data ã§Excelãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
2. create_histogram ã§æŒ‡å®šã‚«ãƒ©ãƒ ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ä½œæˆ
3. analyze_distribution ã§ç¢ºç‡åˆ†å¸ƒã‚’åˆ¤å®š
4. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦æ—¥æœ¬èªã§è©³ç´°ã«å›ç­”

## åˆ¤å®šåŸºæº–
- æ­£è¦åˆ†å¸ƒ: é€£ç¶šãƒ‡ãƒ¼ã‚¿ã§ã€Shapiro-Wilkæ¤œå®šã®på€¤ > 0.05
- ãƒã‚¢ã‚½ãƒ³åˆ†å¸ƒ: é›¢æ•£ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã€åˆ†æ•£/å¹³å‡ â‰ˆ 1.0
- è² ã®äºŒé …åˆ†å¸ƒ: é›¢æ•£ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã€åˆ†æ•£/å¹³å‡ > 1.0ï¼ˆéåˆ†æ•£ï¼‰

## å‡ºåŠ›è¦ä»¶
- å°‚é–€ç”¨èªã«ã¯ç°¡å˜ãªèª¬æ˜ã‚’æ·»ãˆã‚‹
- ãƒ“ã‚¸ãƒã‚¹çš„ãªè§£é‡ˆã¨ç¤ºå”†ã‚’å«ã‚ã‚‹
- åº—èˆ—æ¯”è¼ƒãŒã‚ã‚‹å ´åˆã¯ä¸¡åº—èˆ—ã®é•ã„ã‚’èª¬æ˜
"""


# =============================================================================
# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢
# =============================================================================

class DataStore:
    """ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã™ã‚‹ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¯ãƒ©ã‚¹"""
    _instance = None
    _df: pd.DataFrame | None = None
    _file_path: str | None = None

    @classmethod
    def get_instance(cls):
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance

    def load_data(self, file_path: str) -> pd.DataFrame:
        """Excelãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        self._file_path = file_path
        self._df = pd.read_excel(file_path)
        return self._df

    @property
    def df(self) -> pd.DataFrame | None:
        return self._df

    @property
    def file_path(self) -> str | None:
        return self._file_path


# =============================================================================
# ã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«å®šç¾©
# =============================================================================

@tool(
    "load_store_data",
    "Excelãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰åº—èˆ—ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€åŸºæœ¬æƒ…å ±ã‚’è¿”ã—ã¾ã™ã€‚",
    {
        "type": "object",
        "properties": {
            "file_path": {
                "type": "string",
                "description": "Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ï¼‰"
            }
        }
    }
)
async def load_store_data(args: dict[str, Any]) -> dict[str, Any]:
    """åº—èˆ—ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    try:
        file_path = args.get("file_path", DEFAULT_DATA_PATH)
        store = DataStore.get_instance()
        df = store.load_data(file_path)

        # åŸºæœ¬æƒ…å ±ã‚’å–å¾—
        shops = df["shop"].unique().tolist() if "shop" in df.columns else []
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()

        result = {
            "success": True,
            "file_path": file_path,
            "shape": {"rows": df.shape[0], "columns": df.shape[1]},
            "shops": shops,
            "date_range": {
                "start": str(df["Date"].min()) if "Date" in df.columns else None,
                "end": str(df["Date"].max()) if "Date" in df.columns else None
            },
            "numeric_columns": numeric_cols,
            "available_target_columns": [c for c in TARGET_COLUMNS if c in df.columns]
        }

        return {
            "content": [{"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}]
        }

    except Exception as e:
        return {
            "content": [{"type": "text", "text": f"ã‚¨ãƒ©ãƒ¼: {str(e)}"}],
            "is_error": True
        }


@tool(
    "create_histogram",
    "æŒ‡å®šã‚«ãƒ©ãƒ ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ä½œæˆã—ã€ãƒ“ãƒ³æƒ…å ±ã¨åº¦æ•°ã‚’è¿”ã—ã¾ã™ã€‚åº—èˆ—åˆ¥ã®ãƒ•ã‚£ãƒ«ã‚¿ã‚‚å¯èƒ½ã§ã™ã€‚",
    {
        "type": "object",
        "properties": {
            "column": {
                "type": "string",
                "description": "ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ä½œæˆã™ã‚‹ã‚«ãƒ©ãƒ å"
            },
            "bins": {
                "type": "integer",
                "description": "ãƒ“ãƒ³æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10ï¼‰"
            },
            "shop_filter": {
                "type": "string",
                "description": "åº—èˆ—åã§ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆä¾‹: 'æµæ¯”å¯¿', 'æ¨ªæµœå…ƒç”º'ï¼‰ã€‚çœç•¥æ™‚ã¯å…¨åº—èˆ—"
            },
            "save_image": {
                "type": "boolean",
                "description": "ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ç”»åƒã‚’ä¿å­˜ã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Falseï¼‰"
            }
        },
        "required": ["column"]
    }
)
async def create_histogram(args: dict[str, Any]) -> dict[str, Any]:
    """ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ä½œæˆ"""
    try:
        store = DataStore.get_instance()
        df = store.df

        if df is None:
            return {
                "content": [{"type": "text", "text": "ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã«load_store_dataã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"}],
                "is_error": True
            }

        column = args["column"]
        bins = args.get("bins", 10)
        shop_filter = args.get("shop_filter")
        save_image = args.get("save_image", False)

        if column not in df.columns:
            return {
                "content": [{"type": "text", "text": f"ã‚¨ãƒ©ãƒ¼: ã‚«ãƒ©ãƒ  '{column}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"}],
                "is_error": True
            }

        # åº—èˆ—ãƒ•ã‚£ãƒ«ã‚¿
        data_df = df
        if shop_filter and "shop" in df.columns:
            data_df = df[df["shop"] == shop_filter]
            if len(data_df) == 0:
                return {
                    "content": [{"type": "text", "text": f"ã‚¨ãƒ©ãƒ¼: åº—èˆ— '{shop_filter}' ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"}],
                    "is_error": True
                }

        # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        data = data_df[column].dropna()

        if len(data) == 0:
            return {
                "content": [{"type": "text", "text": f"ã‚¨ãƒ©ãƒ¼: ã‚«ãƒ©ãƒ  '{column}' ã«æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"}],
                "is_error": True
            }

        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã®å ´åˆ
        if data.dtype == 'object':
            value_counts = data.value_counts()
            result = {
                "column": column,
                "column_ja": COLUMN_DEFINITIONS.get(column, column),
                "data_type": "categorical",
                "shop_filter": shop_filter,
                "n_samples": len(data),
                "unique_values": value_counts.index.tolist(),
                "counts": value_counts.values.tolist()
            }
        else:
            # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
            counts, bin_edges = np.histogram(data, bins=bins)

            # åŸºæœ¬çµ±è¨ˆ
            mean_val = float(data.mean())
            std_val = float(data.std())
            min_val = float(data.min())
            max_val = float(data.max())

            result = {
                "column": column,
                "column_ja": COLUMN_DEFINITIONS.get(column, column),
                "data_type": "numeric",
                "shop_filter": shop_filter,
                "n_samples": len(data),
                "bin_edges": [round(x, 2) for x in bin_edges.tolist()],
                "counts": counts.tolist(),
                "statistics": {
                    "mean": round(mean_val, 2),
                    "std": round(std_val, 2),
                    "min": round(min_val, 2),
                    "max": round(max_val, 2)
                }
            }

            # ç”»åƒä¿å­˜
            if save_image:
                fig, ax = plt.subplots(figsize=(10, 6))
                ax.hist(data, bins=bins, edgecolor='black', alpha=0.7)
                ax.set_xlabel(COLUMN_DEFINITIONS.get(column, column))
                ax.set_ylabel('åº¦æ•°')
                title = f'{COLUMN_DEFINITIONS.get(column, column)} ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ '
                if shop_filter:
                    title += f' ({shop_filter})'
                ax.set_title(title)
                ax.axvline(mean_val, color='red', linestyle='--', label=f'å¹³å‡: {mean_val:,.0f}')
                ax.legend()

                # ä¿å­˜
                output_dir = Path("histograms")
                output_dir.mkdir(exist_ok=True)
                filename = f"{column}_{shop_filter or 'all'}.png"
                filepath = output_dir / filename
                plt.savefig(filepath, dpi=150, bbox_inches='tight')
                plt.close()
                result["image_path"] = str(filepath)

        return {
            "content": [{"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}]
        }

    except Exception as e:
        return {
            "content": [{"type": "text", "text": f"ã‚¨ãƒ©ãƒ¼: {str(e)}"}],
            "is_error": True
        }


@tool(
    "analyze_distribution",
    "ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç¢ºç‡åˆ†å¸ƒã‚’åˆ¤å®šã—ã€è©³ç´°ãªçµ±è¨ˆåˆ†æçµæœã‚’è¿”ã—ã¾ã™ã€‚",
    {
        "type": "object",
        "properties": {
            "bin_edges": {
                "type": "array",
                "items": {"type": "number"},
                "description": "ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®ãƒ“ãƒ³å¢ƒç•Œå€¤"
            },
            "counts": {
                "type": "array",
                "items": {"type": "number"},
                "description": "å„ãƒ“ãƒ³ã®åº¦æ•°"
            },
            "column_name": {
                "type": "string",
                "description": "åˆ†æå¯¾è±¡ã®ã‚«ãƒ©ãƒ åï¼ˆçµæœè¡¨ç¤ºç”¨ï¼‰"
            }
        },
        "required": ["bin_edges", "counts"]
    }
)
async def analyze_distribution(args: dict[str, Any]) -> dict[str, Any]:
    """ç¢ºç‡åˆ†å¸ƒã‚’åˆ†æ"""
    try:
        bin_edges = np.array(args["bin_edges"])
        counts = np.array(args["counts"])
        column_name = args.get("column_name", "ä¸æ˜")

        # ãƒ“ãƒ³ä¸­å¿ƒå€¤ã‹ã‚‰æ“¬ä¼¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2
        data = np.repeat(bin_centers, counts.astype(int))

        if len(data) == 0:
            return {
                "content": [{"type": "text", "text": "ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™"}],
                "is_error": True
            }

        n = len(data)
        mean_val = float(np.mean(data))
        variance = float(np.var(data, ddof=1))
        std_dev = float(np.std(data, ddof=1))
        skewness = float(stats.skew(data))
        kurtosis = float(stats.kurtosis(data))

        # åˆ†æ•£/å¹³å‡æ¯”
        dispersion_index = variance / mean_val if mean_val > 0 else float('inf')

        # ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§åˆ¤å®š
        is_discrete = all(float(x).is_integer() for x in data) and data.min() >= 0

        # æ­£è¦æ€§æ¤œå®š
        if len(data) <= 5000:
            shapiro_stat, shapiro_p = stats.shapiro(data)
        else:
            sample = np.random.choice(data, size=5000, replace=False)
            shapiro_stat, shapiro_p = stats.shapiro(sample)

        data_standardized = (data - mean_val) / std_dev if std_dev > 0 else data
        ks_stat, ks_p = stats.kstest(data_standardized, 'norm')

        normality_passed = shapiro_p > 0.05 and ks_p > 0.05

        # åˆ†å¸ƒãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°
        fits = {}

        # æ­£è¦åˆ†å¸ƒ
        mu, sigma = stats.norm.fit(data)
        ll_normal = np.sum(stats.norm.logpdf(data, mu, sigma))
        aic_normal = 4 - 2 * ll_normal
        fits["normal"] = {
            "parameters": {"mu": round(mu, 2), "sigma": round(sigma, 2)},
            "aic": round(aic_normal, 2)
        }

        # ãƒã‚¢ã‚½ãƒ³åˆ†å¸ƒï¼ˆéè² ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
        if mean_val > 0 and data.min() >= 0:
            lambda_poisson = mean_val
            data_int = np.maximum(np.round(data).astype(int), 0)
            ll_poisson = np.sum(stats.poisson.logpmf(data_int, lambda_poisson))
            aic_poisson = 2 - 2 * ll_poisson
            fits["poisson"] = {
                "parameters": {"lambda": round(lambda_poisson, 2)},
                "aic": round(aic_poisson, 2)
            }

        # è² ã®äºŒé …åˆ†å¸ƒ
        if mean_val > 0 and variance > mean_val and data.min() >= 0:
            p = mean_val / variance if variance > 0 else 0.5
            p = max(0.001, min(0.999, p))
            r = mean_val * p / (1 - p) if p < 1 else 1.0
            r = max(0.1, r)
            data_int = np.maximum(np.round(data).astype(int), 0)
            ll_nbinom = np.sum(stats.nbinom.logpmf(data_int, r, p))
            aic_nbinom = 4 - 2 * ll_nbinom
            fits["negative_binomial"] = {
                "parameters": {"r": round(r, 2), "p": round(p, 4)},
                "aic": round(aic_nbinom, 2)
            }

        # æœ€é©åˆ†å¸ƒã®åˆ¤å®š
        valid_fits = {k: v for k, v in fits.items() if np.isfinite(v["aic"])}
        best_by_aic = min(valid_fits.items(), key=lambda x: x[1]["aic"])[0] if valid_fits else "unknown"

        # æœ€çµ‚åˆ¤å®š
        evidence = []
        confidence = 0.0

        if not is_discrete:
            distribution_type = "normal"
            evidence.append("ãƒ‡ãƒ¼ã‚¿ãŒé€£ç¶šå€¤ã§ã‚ã‚‹")
            confidence = 0.7
            if normality_passed:
                evidence.append("æ­£è¦æ€§æ¤œå®šã«ãƒ‘ã‚¹ã—ãŸ")
                confidence += 0.2
            if best_by_aic == "normal":
                evidence.append("AICã§æ­£è¦åˆ†å¸ƒãŒæœ€è‰¯")
                confidence += 0.1
        else:
            if 0.8 <= dispersion_index <= 1.2:
                distribution_type = "poisson"
                evidence.append(f"åˆ†æ•£/å¹³å‡æ¯” = {dispersion_index:.2f} â‰ˆ 1.0")
                confidence = 0.75
            elif dispersion_index > 1.2:
                distribution_type = "negative_binomial"
                evidence.append(f"åˆ†æ•£/å¹³å‡æ¯” = {dispersion_index:.2f} > 1.0ï¼ˆéåˆ†æ•£ï¼‰")
                confidence = 0.75
            else:
                distribution_type = "poisson"
                evidence.append(f"åˆ†æ•£/å¹³å‡æ¯” = {dispersion_index:.2f}")
                confidence = 0.5

        confidence = max(0.0, min(1.0, confidence))

        result = {
            "column": column_name,
            "column_ja": COLUMN_DEFINITIONS.get(column_name, column_name),
            "distribution_type": distribution_type,
            "confidence": round(confidence, 2),
            "statistics": {
                "n_samples": n,
                "mean": round(mean_val, 2),
                "variance": round(variance, 2),
                "std_dev": round(std_dev, 2),
                "skewness": round(skewness, 4),
                "kurtosis": round(kurtosis, 4),
                "dispersion_index": round(dispersion_index, 4)
            },
            "normality_tests": {
                "shapiro_wilk": {"statistic": round(shapiro_stat, 4), "p_value": round(shapiro_p, 4)},
                "kolmogorov_smirnov": {"statistic": round(ks_stat, 4), "p_value": round(ks_p, 4)},
                "passed": normality_passed
            },
            "distribution_fits": fits,
            "best_fit_by_aic": best_by_aic,
            "evidence": evidence,
            "is_discrete": is_discrete
        }

        return {
            "content": [{"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}]
        }

    except Exception as e:
        return {
            "content": [{"type": "text", "text": f"ã‚¨ãƒ©ãƒ¼: {str(e)}"}],
            "is_error": True
        }


@tool(
    "compare_shops",
    "æŒ‡å®šã‚«ãƒ©ãƒ ã«ã¤ã„ã¦åº—èˆ—é–“ã®åˆ†å¸ƒã‚’æ¯”è¼ƒã—ã¾ã™ã€‚",
    {
        "type": "object",
        "properties": {
            "column": {
                "type": "string",
                "description": "æ¯”è¼ƒã™ã‚‹ã‚«ãƒ©ãƒ å"
            }
        },
        "required": ["column"]
    }
)
async def compare_shops(args: dict[str, Any]) -> dict[str, Any]:
    """åº—èˆ—é–“ã®åˆ†å¸ƒã‚’æ¯”è¼ƒ"""
    try:
        store = DataStore.get_instance()
        df = store.df

        if df is None:
            return {
                "content": [{"type": "text", "text": "ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"}],
                "is_error": True
            }

        column = args["column"]
        if column not in df.columns:
            return {
                "content": [{"type": "text", "text": f"ã‚¨ãƒ©ãƒ¼: ã‚«ãƒ©ãƒ  '{column}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"}],
                "is_error": True
            }

        if "shop" not in df.columns:
            return {
                "content": [{"type": "text", "text": "ã‚¨ãƒ©ãƒ¼: åº—èˆ—ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"}],
                "is_error": True
            }

        shops = df["shop"].unique()
        comparison = {}

        for shop in shops:
            shop_data = df[df["shop"] == shop][column].dropna()
            if len(shop_data) > 0 and shop_data.dtype in [np.float64, np.int64]:
                comparison[shop] = {
                    "n_samples": len(shop_data),
                    "mean": round(float(shop_data.mean()), 2),
                    "std": round(float(shop_data.std()), 2),
                    "min": round(float(shop_data.min()), 2),
                    "max": round(float(shop_data.max()), 2),
                    "median": round(float(shop_data.median()), 2)
                }

        # çµ±è¨ˆæ¤œå®šï¼ˆ2åº—èˆ—ã®å ´åˆï¼‰
        test_result = None
        if len(shops) == 2:
            data1 = df[df["shop"] == shops[0]][column].dropna()
            data2 = df[df["shop"] == shops[1]][column].dropna()
            if len(data1) > 0 and len(data2) > 0:
                # tæ¤œå®š
                t_stat, t_p = stats.ttest_ind(data1, data2)
                # Mann-Whitney Uæ¤œå®š
                u_stat, u_p = stats.mannwhitneyu(data1, data2, alternative='two-sided')
                test_result = {
                    "t_test": {"statistic": round(t_stat, 4), "p_value": round(t_p, 4)},
                    "mann_whitney_u": {"statistic": round(u_stat, 4), "p_value": round(u_p, 4)},
                    "significant_difference": t_p < 0.05 or u_p < 0.05
                }

        result = {
            "column": column,
            "column_ja": COLUMN_DEFINITIONS.get(column, column),
            "shops_comparison": comparison,
            "statistical_test": test_result
        }

        return {
            "content": [{"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}]
        }

    except Exception as e:
        return {
            "content": [{"type": "text", "text": f"ã‚¨ãƒ©ãƒ¼: {str(e)}"}],
            "is_error": True
        }


@tool(
    "list_columns",
    "åˆ†æå¯èƒ½ãªã‚«ãƒ©ãƒ ã®ä¸€è¦§ã¨æ—¥æœ¬èªåã‚’è¿”ã—ã¾ã™ã€‚",
    {
        "type": "object",
        "properties": {}
    }
)
async def list_columns(args: dict[str, Any]) -> dict[str, Any]:
    """ã‚«ãƒ©ãƒ ä¸€è¦§ã‚’è¿”ã™"""
    try:
        store = DataStore.get_instance()
        df = store.df

        if df is None:
            # ãƒ‡ãƒ¼ã‚¿æœªèª­ã¿è¾¼ã¿æ™‚ã¯ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚«ãƒ©ãƒ ã®ã¿è¿”ã™
            columns = [
                {"name": col, "name_ja": COLUMN_DEFINITIONS.get(col, col)}
                for col in TARGET_COLUMNS
            ]
        else:
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            columns = [
                {"name": col, "name_ja": COLUMN_DEFINITIONS.get(col, col), "available": col in df.columns}
                for col in TARGET_COLUMNS
                if col in numeric_cols or col in ["shop", "shop_code"]
            ]

        result = {
            "target_columns": columns,
            "total": len(columns)
        }

        return {
            "content": [{"type": "text", "text": json.dumps(result, ensure_ascii=False, indent=2)}]
        }

    except Exception as e:
        return {
            "content": [{"type": "text", "text": f"ã‚¨ãƒ©ãƒ¼: {str(e)}"}],
            "is_error": True
        }


# =============================================================================
# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¯ãƒ©ã‚¹
# =============================================================================

class StoreHistogramAgent:
    """åº—èˆ—ãƒ‡ãƒ¼ã‚¿ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ãƒ»åˆ†å¸ƒåˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""

    def __init__(self, verbose: bool = False):
        self.verbose = verbose

        # MCPã‚µãƒ¼ãƒãƒ¼ä½œæˆ
        self.stats_server = create_sdk_mcp_server(
            name="store_stats",
            version="1.0.0",
            tools=[
                load_store_data,
                create_histogram,
                analyze_distribution,
                compare_shops,
                list_columns
            ]
        )

        self.options = ClaudeAgentOptions(
            system_prompt=SYSTEM_PROMPT,
            mcp_servers={"stats": self.stats_server},
            allowed_tools=[
                "mcp__stats__load_store_data",
                "mcp__stats__create_histogram",
                "mcp__stats__analyze_distribution",
                "mcp__stats__compare_shops",
                "mcp__stats__list_columns"
            ],
            permission_mode="bypassPermissions",
            max_turns=20
        )

        self.total_cost = 0.0
        self.query_count = 0

    async def query(self, question: str) -> str:
        """è‡ªç„¶è¨€èªã§è³ªå•ã—ã€å›ç­”ã‚’å–å¾—"""
        results = []

        async with ClaudeSDKClient(options=self.options) as client:
            await client.query(question)

            async for message in client.receive_response():
                if self.verbose:
                    print(f"[{type(message).__name__}]", end=" ")

                if isinstance(message, AssistantMessage):
                    for block in message.content:
                        if isinstance(block, TextBlock):
                            results.append(block.text)
                        elif isinstance(block, ToolUseBlock) and self.verbose:
                            print(f"\n  Tool: {block.name}")

                elif isinstance(message, ResultMessage):
                    self.total_cost += message.total_cost_usd
                    self.query_count += 1
                    if self.verbose:
                        print(f"\n  Cost: ${message.total_cost_usd:.4f}")

        return "\n".join(results)

    async def analyze_column(self, column: str, shop: str | None = None) -> dict:
        """ç‰¹å®šã‚«ãƒ©ãƒ ã®åˆ†å¸ƒã‚’åˆ†æ"""
        shop_text = f"ï¼ˆ{shop}ï¼‰" if shop else ""
        prompt = f"""
{column}ï¼ˆ{COLUMN_DEFINITIONS.get(column, column)}ï¼‰{shop_text}ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ä½œæˆã—ã€
ç¢ºç‡åˆ†å¸ƒã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®æ‰‹é †ã§å®Ÿè¡Œã—ã¦ãã ã•ã„:
1. load_store_data ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
2. create_histogram ã§ {column} ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ä½œæˆ{'ï¼ˆshop_filter: ' + shop + 'ï¼‰' if shop else ''}
3. analyze_distribution ã§åˆ†å¸ƒã‚’åˆ¤å®š
4. çµæœã‚’æ—¥æœ¬èªã§è©³ã—ãè§£èª¬

ç‰¹ã«ä»¥ä¸‹ã®ç‚¹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„:
- ã©ã®ç¢ºç‡åˆ†å¸ƒã«å¾“ã†ã‹
- ãªãœãã®åˆ†å¸ƒã¨åˆ¤å®šã—ãŸã‹
- ãƒ“ã‚¸ãƒã‚¹çš„ã«ã©ã®ã‚ˆã†ãªæ„å‘³ãŒã‚ã‚‹ã‹
"""
        return await self.query(prompt)

    async def analyze_all_columns(self) -> dict:
        """å…¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚«ãƒ©ãƒ ã‚’åˆ†æ"""
        results = {}

        # ã¾ãšãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
        await self.query("load_store_data ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")

        numeric_targets = [c for c in TARGET_COLUMNS if c not in ["shop", "shop_code"]]

        for column in numeric_targets:
            print(f"\nåˆ†æä¸­: {column} ({COLUMN_DEFINITIONS.get(column, column)})")
            try:
                result = await self.analyze_column(column)
                results[column] = result
            except Exception as e:
                results[column] = f"ã‚¨ãƒ©ãƒ¼: {str(e)}"

        return results

    def get_stats(self) -> dict:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆã‚’å–å¾—"""
        return {
            "query_count": self.query_count,
            "total_cost_usd": round(self.total_cost, 4)
        }


# =============================================================================
# è³ªå•ä¾‹ï¼ˆç¢ºç‡åˆ†å¸ƒé–¢é€£ï¼‰
# =============================================================================

EXAMPLE_QUESTIONS = [
    # åŸºæœ¬çš„ãªåˆ†å¸ƒåˆ†æ
    ("å£²ä¸Šé«˜ã¯ã©ã®ã‚ˆã†ãªç¢ºç‡åˆ†å¸ƒã«å¾“ã£ã¦ã„ã¾ã™ã‹ï¼Ÿ", "Total_Sales"),
    ("å®¢æ•°ã®åˆ†å¸ƒã‚’åˆ†æã—ã¦ãã ã•ã„", "Number_of_guests"),
    ("å–¶æ¥­åˆ©ç›Šã®ç¢ºç‡åˆ†å¸ƒã‚’æ•™ãˆã¦ãã ã•ã„", "Operating_profit"),
    ("åœ¨åº«æœˆæ•°ã¯ã©ã‚“ãªåˆ†å¸ƒã§ã™ã‹ï¼Ÿ", "Months_of_inventory"),

    # åˆ†å¸ƒã®æ¯”è¼ƒ
    ("æµæ¯”å¯¿åº—ã¨æ¨ªæµœå…ƒç”ºåº—ã®å£²ä¸Šé«˜ã®åˆ†å¸ƒã«é•ã„ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ", None),
    ("ä¸¡åº—èˆ—ã®å®¢æ•°ã®åˆ†å¸ƒã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„", None),

    # åˆ†å¸ƒã®è§£é‡ˆ
    ("å£²ä¸Šé«˜ãŒæ­£è¦åˆ†å¸ƒã«å¾“ã†ã¨ã—ãŸã‚‰ã€ã©ã®ã‚ˆã†ãªæ„å‘³ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ", None),
    ("å®¢æ•°ãŒãƒã‚¢ã‚½ãƒ³åˆ†å¸ƒã«å¾“ã†å ´åˆã€ãƒ“ã‚¸ãƒã‚¹ä¸Šã®ç¤ºå”†ã¯ä½•ã§ã™ã‹ï¼Ÿ", None),

    # çµ±è¨ˆçš„æ¤œå®š
    ("å£²ä¸Šé«˜ã¯æ­£è¦åˆ†å¸ƒã«å¾“ã£ã¦ã„ã‚‹ã¨è¨€ãˆã¾ã™ã‹ï¼Ÿæ¤œå®šçµæœã‚’æ•™ãˆã¦ãã ã•ã„", None),
    ("ç²—åˆ©ã®ãƒ‡ãƒ¼ã‚¿ã«éåˆ†æ•£ã¯è¦‹ã‚‰ã‚Œã¾ã™ã‹ï¼Ÿ", "gross_profit"),

    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è§£é‡ˆ
    ("å£²ä¸Šé«˜ã®å¹³å‡ã¨æ¨™æº–åå·®ã‹ã‚‰ã€ã©ã®ç¨‹åº¦ã®ã°ã‚‰ã¤ããŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ", None),
    ("å®¢å˜ä¾¡ã®åˆ†å¸ƒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è§£é‡ˆã—ã¦ãã ã•ã„", "Price_per_customer"),

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ
    ("ç”·æ€§ç”¨å•†å“ã¨å¥³æ€§ç”¨å•†å“ã®å£²ä¸Šåˆ†å¸ƒã«é•ã„ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ", None),
    ("å­£ç¯€å¤‰å‹•ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€å£²ä¸Šé«˜ã®åˆ†å¸ƒã¯ã©ã†ãªã‚Šã¾ã™ã‹ï¼Ÿ", None),
]


# =============================================================================
# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰
# =============================================================================

def print_welcome_screen():
    """ã‚¦ã‚§ãƒ«ã‚«ãƒ ç”»é¢ã‚’è¡¨ç¤º"""
    print()
    print("â•”" + "â•" * 58 + "â•—")
    print("â•‘" + " " * 58 + "â•‘")
    print("â•‘   ğŸª åº—èˆ—ãƒ‡ãƒ¼ã‚¿ ç¢ºç‡åˆ†å¸ƒåˆ†æ AI Agent                   â•‘")
    print("â•‘   Q-Storm EDA - Distribution Analyzer                   â•‘")
    print("â•‘" + " " * 58 + "â•‘")
    print("â•‘   æµæ¯”å¯¿åº—ãƒ»æ¨ªæµœå…ƒç”ºåº—ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€            â•‘")
    print("â•‘   ç¢ºç‡åˆ†å¸ƒã‚’åˆ¤å®šã—ã¦è‡ªç„¶è¨€èªã§è§£èª¬ã—ã¾ã™ã€‚              â•‘")
    print("â•‘" + " " * 58 + "â•‘")
    print("â•š" + "â•" * 58 + "â•")
    print()


def print_help():
    """ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º"""
    print()
    print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚ ğŸ“– ä½¿ã„æ–¹                                               â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print("â”‚                                                         â”‚")
    print("â”‚ ğŸ”¹ è‡ªç„¶è¨€èªã§è³ªå•:                                      â”‚")
    print("â”‚    ã€Œå£²ä¸Šé«˜ã®åˆ†å¸ƒã‚’æ•™ãˆã¦ã€                             â”‚")
    print("â”‚    ã€Œå®¢æ•°ã¯ã©ã‚“ãªç¢ºç‡åˆ†å¸ƒã«å¾“ã†ï¼Ÿã€                     â”‚")
    print("â”‚    ã€Œæµæ¯”å¯¿åº—ã¨æ¨ªæµœå…ƒç”ºåº—ã®å£²ä¸Šã‚’æ¯”è¼ƒã—ã¦ã€             â”‚")
    print("â”‚                                                         â”‚")
    print("â”‚ ğŸ”¹ ã‚³ãƒãƒ³ãƒ‰:                                            â”‚")
    print("â”‚    /examples  - è³ªå•ä¾‹ã‚’è¡¨ç¤º                            â”‚")
    print("â”‚    /columns   - åˆ†æå¯èƒ½ãªã‚«ãƒ©ãƒ ä¸€è¦§                    â”‚")
    print("â”‚    /analyze <ã‚«ãƒ©ãƒ å> - ç‰¹å®šã‚«ãƒ©ãƒ ã®åˆ†å¸ƒåˆ†æ           â”‚")
    print("â”‚    /compare <ã‚«ãƒ©ãƒ å> - åº—èˆ—é–“æ¯”è¼ƒ                     â”‚")
    print("â”‚    /help      - ã“ã®ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º                        â”‚")
    print("â”‚    exit       - çµ‚äº†                                    â”‚")
    print("â”‚                                                         â”‚")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print()


def print_example_questions():
    """è³ªå•ä¾‹ã‚’è¡¨ç¤º"""
    print()
    print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚ ğŸ’¡ è³ªå•ä¾‹ï¼ˆç¢ºç‡åˆ†å¸ƒé–¢é€£ï¼‰                               â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")

    categories = {
        "åˆ†å¸ƒåˆ†æ": EXAMPLE_QUESTIONS[:4],
        "åº—èˆ—æ¯”è¼ƒ": EXAMPLE_QUESTIONS[4:6],
        "åˆ†å¸ƒã®è§£é‡ˆ": EXAMPLE_QUESTIONS[6:8],
        "çµ±è¨ˆçš„æ¤œå®š": EXAMPLE_QUESTIONS[8:10],
        "ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è§£é‡ˆ": EXAMPLE_QUESTIONS[10:12],
    }

    for category, questions in categories.items():
        print(f"â”‚                                                         â”‚")
        print(f"â”‚ ã€{category}ã€‘                                          â”‚"[:60])
        for i, (q, _) in enumerate(questions, 1):
            # è³ªå•ã‚’é©åˆ‡ãªé•·ã•ã«åˆ‡ã‚Šè©°ã‚
            q_display = q if len(q) <= 45 else q[:42] + "..."
            print(f"â”‚   {i}. {q_display:<51} â”‚"[:60])

    print("â”‚                                                         â”‚")
    print("â”‚ ç•ªå·ã‚’å…¥åŠ›ã™ã‚‹ã¨ãã®è³ªå•ã‚’å®Ÿè¡Œã—ã¾ã™ï¼ˆä¾‹: 1ï¼‰          â”‚")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print()


def print_columns_summary():
    """ã‚«ãƒ©ãƒ ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
    print()
    print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚ ğŸ“Š åˆ†æå¯èƒ½ãªã‚«ãƒ©ãƒ                                      â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")

    for col in TARGET_COLUMNS:
        if col not in ["shop", "shop_code"]:
            ja_name = COLUMN_DEFINITIONS.get(col, col)
            print(f"â”‚   {col:<25} {ja_name:<20} â”‚"[:60])

    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print()


async def interactive_mode():
    """å¯¾è©±å‹ãƒ¢ãƒ¼ãƒ‰"""
    print_welcome_screen()
    print_help()

    agent = StoreHistogramAgent(verbose=False)

    # åˆå›ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
    try:
        await agent.query("load_store_data ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚èª­ã¿è¾¼ã¿çµæœã‚’ç°¡æ½”ã«å ±å‘Šã—ã¦ãã ã•ã„ã€‚")
        print("âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†")
    except Exception as e:
        print(f"âš ï¸  ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    print()
    print("=" * 60)
    print("è‡ªç„¶è¨€èªã§ç¢ºç‡åˆ†å¸ƒã«é–¢ã™ã‚‹è³ªå•ã‚’ã—ã¦ãã ã•ã„ã€‚")
    print("/examples ã§è³ªå•ä¾‹ã‚’è¡¨ç¤ºã€/help ã§ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º")
    print("=" * 60)

    while True:
        try:
            print()
            user_input = input("ğŸ” è³ªå•ã‚’å…¥åŠ›> ").strip()

            if not user_input:
                continue

            # çµ‚äº†ã‚³ãƒãƒ³ãƒ‰
            if user_input.lower() in ("exit", "quit", "q", "çµ‚äº†"):
                print()
                print("=" * 60)
                print(f"ğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ: {agent.get_stats()}")
                print("ğŸ‘‹ ã”åˆ©ç”¨ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸï¼")
                print("=" * 60)
                break

            # ãƒ˜ãƒ«ãƒ—
            if user_input.lower() in ("/help", "help", "?", "ãƒ˜ãƒ«ãƒ—"):
                print_help()
                continue

            # è³ªå•ä¾‹è¡¨ç¤º
            if user_input.lower() in ("/examples", "/ex", "ä¾‹", "è³ªå•ä¾‹"):
                print_example_questions()
                continue

            # ç•ªå·ã«ã‚ˆã‚‹è³ªå•é¸æŠ
            if user_input.isdigit():
                idx = int(user_input) - 1
                if 0 <= idx < len(EXAMPLE_QUESTIONS):
                    question, column = EXAMPLE_QUESTIONS[idx]
                    print(f"\né¸æŠã•ã‚ŒãŸè³ªå•: {question}")
                    user_input = question
                else:
                    print(f"âš ï¸  1ã€œ{len(EXAMPLE_QUESTIONS)} ã®ç•ªå·ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                    continue

            # ã‚«ãƒ©ãƒ ä¸€è¦§
            if user_input.lower() in ("/columns", "/cols", "ã‚«ãƒ©ãƒ "):
                print_columns_summary()
                continue

            # åˆ†æã‚³ãƒãƒ³ãƒ‰
            if user_input.startswith("/analyze "):
                column = user_input[9:].strip()
                print(f"\nğŸ“Š {column} ({COLUMN_DEFINITIONS.get(column, column)}) ã‚’åˆ†æä¸­...")
                response = await agent.analyze_column(column)
            elif user_input.startswith("/compare "):
                column = user_input[9:].strip()
                print(f"\nğŸ“Š {column} ã®åº—èˆ—é–“æ¯”è¼ƒã‚’å®Ÿè¡Œä¸­...")
                response = await agent.query(
                    f"compare_shops ã§ {column} ã‚’åº—èˆ—é–“ã§æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚"
                    f"çµ±è¨ˆçš„æ¤œå®šã®çµæœã¨ã€ãƒ“ã‚¸ãƒã‚¹çš„ãªè§£é‡ˆã‚’æ—¥æœ¬èªã§è©³ã—ãè§£èª¬ã—ã¦ãã ã•ã„ã€‚"
                )
            else:
                # è‡ªç„¶è¨€èªè³ªå•
                print("\nğŸ¤” åˆ†æä¸­...")
                response = await agent.query(user_input)

            # å›ç­”è¡¨ç¤º
            print()
            print("â”Œ" + "â”€" * 58 + "â”")
            print("â”‚ ğŸ“ å›ç­”                                                 â”‚")
            print("â””" + "â”€" * 58 + "â”˜")
            print()
            print(response)
            print()
            print(f"ğŸ’° ç´¯è¨ˆã‚³ã‚¹ãƒˆ: ${agent.total_cost:.4f}")

        except KeyboardInterrupt:
            print(f"\n\nğŸ“Š çµ±è¨ˆ: {agent.get_stats()}")
            print("ä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
            break
        except Exception as e:
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")


# =============================================================================
# ãƒ¡ã‚¤ãƒ³
# =============================================================================

async def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    args = sys.argv[1:]

    if "--column" in args:
        idx = args.index("--column")
        if idx + 1 < len(args):
            column = args[idx + 1]
            agent = StoreHistogramAgent(verbose=True)
            result = await agent.analyze_column(column)
            print(result)
            print(f"\nçµ±è¨ˆ: {agent.get_stats()}")
        else:
            print("ã‚¨ãƒ©ãƒ¼: --column ã«ã¯å¼•æ•°ãŒå¿…è¦ã§ã™")
    elif "--all" in args:
        agent = StoreHistogramAgent(verbose=True)
        results = await agent.analyze_all_columns()
        print(f"\nå®Œäº†: {len(results)} ã‚«ãƒ©ãƒ åˆ†æ")
        print(f"çµ±è¨ˆ: {agent.get_stats()}")
    else:
        await interactive_mode()


if __name__ == "__main__":
    asyncio.run(main())
